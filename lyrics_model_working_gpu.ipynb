{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7262129719995881890\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4934185779\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13335580058563771292\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()) \n",
    "#if you wnt to use your gpu and this command doesnt list it, close jupyter session (ctrl+c in cmd) and this notebook\n",
    "#copy all 3 commands and launch jupyter notebook again\n",
    "#if it still does not list check hardware and software compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'D:\\lyrics_gen\\rap_lyrics\\rap_lyrics_final\\lyrics' #insert your path to lyrics\n",
    "\n",
    "'''for filename in os.listdir(directory):\n",
    "    print(filename)'''\n",
    "    \n",
    "lyrics = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        path = os.path.join(directory, filename)\n",
    "        with open(path) as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                lyrics.append(data[\"Lyrics\"])\n",
    "            except: continue\n",
    "    else: continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lyrics = []\n",
    "for song in lyrics:\n",
    "    for verse in song:\n",
    "        for word in verse:\n",
    "            for letter in word:\n",
    "                flat_lyrics.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4117866"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique characters in the file\n",
    "good = ['\\n', ' ', '!', '\"', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lyrics_clean = []\n",
    "for letter in flat_lyrics: \n",
    "    if letter in good: flat_lyrics_clean.append(letter)\n",
    "    else: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4080064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_lyrics_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 unique characters\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(flat_lyrics_clean))\n",
    "print ('{} unique characters'.format(len(vocab)))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in flat_lyrics_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '&' :   4,\n",
      "  \"'\" :   5,\n",
      "  ',' :   6,\n",
      "  '-' :   7,\n",
      "  '.' :   8,\n",
      "  '0' :   9,\n",
      "  '1' :  10,\n",
      "  '2' :  11,\n",
      "  '3' :  12,\n",
      "  '4' :  13,\n",
      "  '5' :  14,\n",
      "  '6' :  15,\n",
      "  '7' :  16,\n",
      "  '8' :  17,\n",
      "  '9' :  18,\n",
      "  ':' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'N', 'o', 'b', 'o', 'd', 'y', ' ', 'p', 'r', 'a', 'y', ' '] ---- characters mapped to int ---- > [ 0 35 64 51 64 53 74  1 65 67 50 74  1]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(flat_lyrics_clean[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "N\n",
      "o\n",
      "b\n",
      "o\n",
      "d\n",
      "y\n",
      " \n",
      "p\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 1024\n",
    "examples_per_epoch = len(flat_lyrics_clean)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(10):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\\nNobody pray for me\\nIt's been that day for me\\nWay Yeah, yeah!\\n\\n\\nAyy, I remember syrup sandwiches and crime allowances\\nFinesse a nigga with some counterfeits, but now Im countin' this\\nParmesan where my accountant lives, in fact I'm downin this\\nD'USS with my boo bae tastes like Kool-Aid for the analysts\\nGirl, I can buy yo' ass the world with my paystub\\nOoh, that pussy good, won't you sit it on my taste bloods?\\nI get way too petty once you let me do the extras\\nPull up on your block, then break it down: we playin' Tetris\\nA.M. to the P.M., P.M. to the A.M., funk\\nPiss out your per diem, you just gotta hate 'em, funk\\nIf I quit your BM, I still ride Mercedes, funk\\nIf I quit this season, I still be the greatest, funk\\nMy left stroke just went viral\\nRight stroke put lil' baby in a spiral\\nSoprano C, we like to keep it on a high note\\nIt's levels to it, you and I know\\n\\n\\nBitch, be humble Hol up, bitch\\nSit down Hol up, lil', hol up, lil' bitch\\nBe humble Hol' up, bitch\\nSit down Hol' up, sit down, lil, sit down, lil' bitch\\nBe h\"\n",
      "\"umble Hol' up, hol' up\\nBitch, sit down Hol' up, hol' up, lil' bitch\\nBe humble Lil' bitch, hol' up, bitch\\nSit down Hol' up, hol' up, hol' up, hol' up\\nBe humble Hol' up, hol' up\\nSit down Hol' up, hol' up, lil', hol' up, lil' bitch\\nBe humble Hol' up, bitch\\nSit down Hol' up, sit down, lil', sit down, lil' bitch\\nBe humble Hol' up, hol' up\\nBitch, sit down Hol' up, hol' up, lil' bitch\\nBe humble Lil' bitch, hol' up, bitch\\nSit down Hol' up, hol' up, hol' up, hol' up\\n\\n\\nWho dat nigga thinkin' that he frontin' on Man-Man? Man-Man\\nGet the fuck off my stage, I'm the Sandman Sandman\\nGet the fuck off my dick, that ain't right\\nI make a play fucking up your whole life\\nI'm so fuckin' sick and tired of the Photoshop\\nShow me somethin' natural like afro on Richard Pryor\\nShow me somethin' natural like ass with some stretch marks\\nStill will take you down right on your mama's couch in Polo socks\\nAyy, this shit way too crazy, ayy, you do not amaze me, ayy\\nI blew cool from AC, ayy, Obama just paged me, ayy\\nI don't fabricate it, ayy, mos\"\n",
      "\"t of y'all be fakin', ayy\\nI stay modest 'bout it, ayy, she elaborate it, ayy\\nThis that Grey Poupon, that Evian, that TED Talk, ayy\\nWatch my soul speak, you let the meds talk, ayy\\nIf I kill a nigga, it won't be the alcohol, ayy\\nI'm the realest nigga after all\\n\\n\\nBitch, be humble Hol' up, bitch\\nSit down Hol' up, lil', hol' up, lil' bitch\\nBe humble Hol' up, bitch\\nSit down Hol' up, sit down, lil', sit down, lil' bitch\\nBe humble Hol' up, hol' up\\nBitch, sit down Hol' up, hol' up, lil' bitch\\nBe humble Lil' bitch, hol' up, bitch\\nSit down Hol' up, hol' up, hol' up, hol' up\\nBe humble Hol' up, hol' up\\nSit down Hol' up, hol' up, lil', hol' up, lil' bitch\\nBe humble Hol' up, bitch\\nSit down Hol' up, sit down, lil', sit down, lil' bitch\\nBe humble Hol' up, hol' up\\nBitch, sit down Hol' up, hol' up, lil' bitch\\nBe humble Lil' bitch, hol' up, bitch\\nSit down Hol' up, hol' up, hol' up, hol' up\\nDamn, love or lust\\nDamn, all of us\\n\\n\\nGive me a run for my money\\nThere is nobody, no one to outrun me\\nAnother world premiere!\\nSo give me a run \"\n",
      "\"for my money\\nSippin' bubbly, feelin lovely, livin' lovely\\nJust love me\\nI wanna be with you, ayy, I wanna be with\\nJust love me, just love me, just love\\nI wanna be with you, ayy, I wanna be with\\nLove me\\nI wanna be with you\\nLove me, just love me\\n\\n\\nIf I didn't ride blade on curb, would you still love me?\\nIf I made up my mind in work, would you still love me?\\nKeep it a hundred, Id rather you trust me than to love me\\nKeep it a whole one hund': don't got you, I got nothin'\\n\\n\\nAyy, I got somethin'\\nHol' up, we gon' function, ayy, no assumptions, ayy\\nFeelin' like Tyson with it\\nKnock it out twice, Im with it\\nOnly for the night, Im kiddin'\\nOnly for life, yeah, only for life, yeah\\nOnly for life, lets get it\\nHit that shoulder lean\\nI know what comin' over me\\nBackstroke oversea\\nI know what you need\\nAlready on ten, all money come in\\nAll feeling go out, this feeling don't drought\\nThis party won't end\\n\\n\\nIf I didnt ride blade on curb, would you still love me?\\nIf I minimized my net-worth, would you still love me?\\nKeep it a hundred,\"\n",
      "\" I'd rather you trust me than to love me\\nKeep it a whole one hund': don't got you, I got nothin'\\n\\n\\nGive me a run for my money\\nThere is nobody, no one to outrun me\\nSo give me a run for my money\\nSippin' bubbly, feelin' lovely, livin' lovely\\nJust love me\\nI wanna be with you, ayy, I wanna be with\\nJust love me, just love me, just love\\nI wanna be with you, ayy, I wanna be with\\nLove me\\nI wanna be with you\\nLove me, just love me\\n\\n\\nI'm on the way\\nWe ain't got no time to waste\\nPoppin' your gum on the way love me\\nAm I in the way?\\nI don't wan' pressure you none\\nI want your blessing today love me\\nOh, by the way, open the door by the way\\nTold you that I'm on the way love me\\nI'm on the way, I know connection is vague\\nPick up the phone for me, babe\\nDammit, we jammin'\\nBad attitude from yo' nanny\\nCurves and your hips from yo' mammy\\nRemember Gardena, I took the studio camera\\nI know Top will be mad at me\\nI had to do it, I want your body, your music\\nI bought the big one to prove it\\nLook what you made\\nTold you that I'm on the way\\nI'\"\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"\\nNobody pray for me\\nIt's been that day for me\\nWay Yeah, yeah!\\n\\n\\nAyy, I remember syrup sandwiches and crime allowances\\nFinesse a nigga with some counterfeits, but now Im countin' this\\nParmesan where my accountant lives, in fact I'm downin this\\nD'USS with my boo bae tastes like Kool-Aid for the analysts\\nGirl, I can buy yo' ass the world with my paystub\\nOoh, that pussy good, won't you sit it on my taste bloods?\\nI get way too petty once you let me do the extras\\nPull up on your block, then break it down: we playin' Tetris\\nA.M. to the P.M., P.M. to the A.M., funk\\nPiss out your per diem, you just gotta hate 'em, funk\\nIf I quit your BM, I still ride Mercedes, funk\\nIf I quit this season, I still be the greatest, funk\\nMy left stroke just went viral\\nRight stroke put lil' baby in a spiral\\nSoprano C, we like to keep it on a high note\\nIt's levels to it, you and I know\\n\\n\\nBitch, be humble Hol up, bitch\\nSit down Hol up, lil', hol up, lil' bitch\\nBe humble Hol' up, bitch\\nSit down Hol' up, sit down, lil, sit down, lil' bitch\\nBe \"\n",
      "Target data: \"Nobody pray for me\\nIt's been that day for me\\nWay Yeah, yeah!\\n\\n\\nAyy, I remember syrup sandwiches and crime allowances\\nFinesse a nigga with some counterfeits, but now Im countin' this\\nParmesan where my accountant lives, in fact I'm downin this\\nD'USS with my boo bae tastes like Kool-Aid for the analysts\\nGirl, I can buy yo' ass the world with my paystub\\nOoh, that pussy good, won't you sit it on my taste bloods?\\nI get way too petty once you let me do the extras\\nPull up on your block, then break it down: we playin' Tetris\\nA.M. to the P.M., P.M. to the A.M., funk\\nPiss out your per diem, you just gotta hate 'em, funk\\nIf I quit your BM, I still ride Mercedes, funk\\nIf I quit this season, I still be the greatest, funk\\nMy left stroke just went viral\\nRight stroke put lil' baby in a spiral\\nSoprano C, we like to keep it on a high note\\nIt's levels to it, you and I know\\n\\n\\nBitch, be humble Hol up, bitch\\nSit down Hol up, lil', hol up, lil' bitch\\nBe humble Hol' up, bitch\\nSit down Hol' up, sit down, lil, sit down, lil' bitch\\nBe h\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 35 ('N')\n",
      "Step    1\n",
      "  input: 35 ('N')\n",
      "  expected output: 64 ('o')\n",
      "Step    2\n",
      "  input: 64 ('o')\n",
      "  expected output: 51 ('b')\n",
      "Step    3\n",
      "  input: 51 ('b')\n",
      "  expected output: 64 ('o')\n",
      "Step    4\n",
      "  input: 64 ('o')\n",
      "  expected output: 53 ('d')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((75, 1024), (75, 1024)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!You may need to lower batch and buffer sized if your pc is a little bit slower!\n",
    "#if thats the case try lowering batch size to 64 and buffer size to 10000 or even lower\n",
    "\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 75\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 50000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 1024, 76) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (75, None, 256)           19456     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (75, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (75, None, 76)            77900     \n",
      "=================================================================\n",
      "Total params: 4,035,660\n",
      "Trainable params: 4,035,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 44, 61, ..., 11, 38,  1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " \"rip, drip\\nCame through drippin' drip, drip\\nCame through drippin' drip, drip\\nDiamonds on my wrist, they drippin' ice!\\nCame through drippin' drip, drip\\nCame through drippin' drip, drip\\nCame through drippin' drip, drip\\nDiamonds on my wrist, they drippin' ice!\\n\\n\\nGive me little something to remember Cardi!\\nTryna make love in a Sprinter yeah\\nQuick to drop a nigga like Kemba go\\nLookin' like a right swipe on Tinder woo\\nShit on these hoes shit\\nLight up my wrist on these hoes wrist\\nNow I look down on these bitches down\\nI feel like I'm on stilts on these hoes woo\\nFuck ya' baby daddy right now right now\\nAnna Mae, got cake by the pound pound\\nGo down, eat it up, don't drown\\nMac n' cheese in the bowl, how it sound? sound\\nI got that gushy\\nYeah that's a fact, but I never been pussy\\nI've been that bitch since pajamas with footies\\nWon MVP, and I'm still a rookie, like woo\\nI gotta work on my anger ayy\\nMight kill a bitch with my fingers ayy\\nI gotta stay outta Gucci woo\\nI'm finna run outta hangers woo\\nIs she a stripper, a rapper o\"\n",
      "\n",
      "Next Char Predictions: \n",
      " '[WlZOj0iHJ;daex;q871,qWkn56B?lVuH4SeWJ Yq7,olt3P2qLuoOc4?cMGr,m0-1PdHm.u h-,q!ZpJWs:r3RH;rMIse\"Rm0n sB]R\"n5hEkhA\"R2Et]b8xrt0KPc;:Em Ca;JslGvc32M\\'cXcdwPSLuPMOZNf ig o25&VrYc4\\nuOLKHP\"RtVp i8PZ.H\"5,a7RqB]YOCaCkiEAa6NMNV&Kb6P7!6;9.JMbWjgQ0qJOhr9U4XUkGpGK[iaNd\"yv7XLjeXGiSEFTK\"EJtYa,DAPz[R7h[3QgMUnZCD k!aFklFVu?lbVuUHQJi69 OA[ h8kN\\np4qTBF[ay.ZEmbk-1kd8g\"m8xeLfR4pmDodHmD\"l y[mQu6fNt5[ c1rZx.t75jGr,1onvncq\"Vrq-wmh2tH?\\nSDvri8jSR:CDGoEvpyX:.WfIqQC,JKuZu,rA\\nr75LB.:L&klDG-[?o:;loZZ609c0Tlbd\\nLDkfx]GWnG]koW-LoM5iipxO4NsYCpRk3u3x3J;Wt]H,Oc.hR8EYlnf&],?gqzV5KXTy4nAV;wq6hq!&q2Ak0QfP97GJedKN&Qf sG0Vi4jG \\'K;vq!1KBJZmn,yiGpmClcvpW.-xuGuC:QwokmY eS9L ]kh0w:B-Kc\\'DsyFhlQ-ePv ?B:EG[M\"yt\"x[u1meK];e1QtKCffEE!IEElhnefrN3O?.NxJ;AP0GD-YX5DZDO59DCf-gk[Wy3M]mb\\'FGj ;5J2Vm6 1ie947,rgy-gTu6cmuI&fcq:[&Kk QI!5c560BL80RbaKDKN74odLs[0S]R[-;\",EgKSPCbYX0Us8WhVkHPkPkc.;JjJjN5oXTC3P57U\"295ztH!ogTDBtP?0fjetz\\'\\'50aJ!7?,n;F-1X\\'mhH\\'jaJjfP3Hj68T4\"kwW4AnpYO0Rida!Jsxz.\\'OswD.6b:bAca3cYj1aCSjMEF.B\\n w[P1?p6zYD9i ;\\nbyf9KL5?iD1FLYYd9niM1v;,?t 9qkG6v[Vl.d\\'b\\'G]q2Q '\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (75, 1024, 76)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.33152\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to use our model in stead of training one skip straigh to loading model\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 53 steps\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 41s 776ms/step - loss: 3.2525\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 2.4102\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 2.2091\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 2.0301\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 1.8809\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 1.7631\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 1.6714\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 1.6006\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.5434\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.4963\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.4573\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.4233\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.3936\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.3661\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.3419\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 40s 752ms/step - loss: 1.3195\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.2978\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 1.2772\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.2580\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.2395\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 1.2208\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 1.2030\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 1.1859\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.1680\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 1.1512\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.1347\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.1171\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.0997\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.0827\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.0661\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.0488\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 1.0310\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 1.0148\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.9972\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.9787\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.9601\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.9437\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.9268\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 0.9094\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.8932\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 0.8743\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 0.8591\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.8419\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.8248\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.8109\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.7991\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.7829\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.7716\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.7569\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 40s 752ms/step - loss: 0.7443\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.7354\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 40s 757ms/step - loss: 0.7242\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 40s 756ms/step - loss: 0.7149\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 0.7050\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.6988\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.6927\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.6840\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 0.6773\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 40s 755ms/step - loss: 0.6704\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 40s 753ms/step - loss: 0.6655\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 40s 754ms/step - loss: 0.6608\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 40s 761ms/step - loss: 0.6540\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 43s 810ms/step - loss: 0.6489\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 41s 765ms/step - loss: 0.6462\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.6395\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 41s 779ms/step - loss: 0.6380\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 41s 779ms/step - loss: 0.6277\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.6250\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.6217\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 41s 776ms/step - loss: 0.6173\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.6143\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 41s 777ms/step - loss: 0.6103\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 41s 777ms/step - loss: 0.6071\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 41s 777ms/step - loss: 0.6036\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5994\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.5962\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 41s 776ms/step - loss: 0.5935\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 41s 776ms/step - loss: 0.5910\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5887\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 41s 776ms/step - loss: 0.5834\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.5812\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 41s 778ms/step - loss: 0.5796\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 41s 776ms/step - loss: 0.5752\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5728\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.5720\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5678\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 41s 777ms/step - loss: 0.5648\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 41s 780ms/step - loss: 0.5610\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5619\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 41s 779ms/step - loss: 0.5589\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 41s 778ms/step - loss: 0.5571\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5539\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5495\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.5491\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 41s 779ms/step - loss: 0.5468\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.5437\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 41s 777ms/step - loss: 0.5415\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 41s 778ms/step - loss: 0.5408\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 41s 779ms/step - loss: 0.5385\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.5343\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_100'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            19456     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 76)             77900     \n",
      "=================================================================\n",
      "Total params: 4,035,660\n",
      "Trainable params: 4,035,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can load provided model using this command\n",
    "#if you have trainded your own model skip this step\n",
    "model = tf.keras.models.load_model('good_model_100_epochs.h5', compile=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate, temperature):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = num_generate\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  # You can try experimenting with values between 0 and 2 but values lower than 0.6 are very likely to just copy existing lyrics\n",
    "  # and values higher than 1.5 are going to be random gibberish (remember to use . not ,)\n",
    "  temperature = temperature\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke and raised your block\n",
      "So image is down with it should be anywhere...\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie, you ain't never told no lie\n",
      "Real niggas say word\n",
      "You ain't never told no lie\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Smoke \", num_generate = 1500, temperature = 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke an apple!\n",
      "Somebody need mat fighting out they magning\n",
      "Cause ain't no broke by ain't mine\n",
      "She want more than put ya would you still don't know if\n",
      "If I'll ever listen to my mama\n",
      "I don't really hang with Time\n",
      "\n",
      "\n",
      "What's the difference between det in?\n",
      "Heard you the shit that you came with, who you came in this hotel room\n",
      "You may get a bit\n",
      "When you make it, eat on that pain\n",
      "I'm sorry I made my dick for just a lot of constants\n",
      "But changes dispose blunts, three hoes stucked\n",
      "She tried to act like they watch Thatless game\n",
      "What you thought? You want beef? I like the way you be loated\n",
      "Cause it's all for the kind of bitches, they don't love you no more\n",
      "They don't love you no more\n",
      "Don't fly, I don't get signed by 12\n",
      "Bitch conted upon Double Rich Rose alive\n",
      "Wait, honey, choose to success so its gone be a freak\n",
      "Cause niggas talkin' bout piney gon' hate\n",
      "But I know that I know it, I know I chose ain't nothin' better\n",
      "Now it's time to change, sometimes it dip, make it dip, make it dip, make it dip Ayy, ayy\n",
      "So try not to fall asleep, you know his bars dont be snippin'\n",
      "Now she really want my rap got nipstally ways\n",
      "I was up late night ballin'\n",
      "Countin' up hundreds by the thousand\n",
      "I was up late night ballin'\n",
      "Countin' up hundreds by the thousand\n",
      "I was up late night ballin'\n",
      "Countin' up my bonds\n",
      "\n",
      "\n",
      "A fuck nigga, that's that shit I don't like right now\n",
      "A bitch nigga, that's that shit I don't like\n",
      "Young Choppa, got me girls and they ain't usin' hands\n",
      "Two 3sanny, nce talkin' money, then rap schemes\n",
      "Goddamn, \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Smoke \", num_generate = 1500, temperature = 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke and robbin' bitch\n",
      "'Cause you murdered over like a T-Rex Ro\n",
      "Niggas got firently like, \"bitch\" deep and formally talkin'\n",
      "\"What the fuck, go watch, today 5 mill\n",
      "He said \"Yo baby tell 'em, we don't take rap lame\n",
      "Yeah aight, I'm 'bout that Bambi Ahhhh\n",
      "My life is finally from Hova Lito die USNeV\n",
      "Ebus taste on that cookie\n",
      "Fucking rappin' about Zooony Pity\n",
      "I was only missin' on the level to add-to-ta\n",
      "No one calling us while Jevis holler-bain\n",
      "\n",
      "\n",
      "No we are even got nothing to lost\n",
      "\n",
      "\n",
      "Don't stop, pop that Hoffa, I'm violence\n",
      "If Brookly Winton, I was toling on rap\n",
      "And when you suck it, I bust, real shit\n",
      "It's a day, she look at her drip-drip\n",
      "Diamonds gotta find them noish, no way, no o-to-day\n",
      "I'll put my time the watch, I'm on a new levovat\n",
      "We came regular, never chase a fuck nigga\n",
      "J my nigga Ema usual Long Beachts\n",
      "\n",
      "\n",
      "You ain't thinkin' 'bout your issue?\n",
      "Whole squad, just is cutter seats\n",
      "No cryin'\n",
      "To black and white, hop Davis, my cock\n",
      "You know I be thuggin', on my hood shit\n",
      "Niggas still love me Ooh, ayy, ayy\n",
      "\n",
      "\n",
      "So long Keine, got my back and till they kill me UK\n",
      "Soon as a thumb lights can against me\n",
      "See, like bumpin' the shame off a thop-tait, uh, uh\n",
      "But I'll prot it on life\n",
      "I've been divin to feel\n",
      "I don't want to see them Nows\n",
      "To look always start tank me\n",
      "Callin' my phone, it's evident\n",
      "They say they watching papers, guessin' I'm ice, but I'm lovin' you, lovin' you\n",
      "It's beat feelings like I'm always can't feel your best of me, yeah\n",
      "I don't feel nobody talking record stands for someone else\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Smoke \", num_generate = 1500, temperature = 1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke anyo sex, no a tripy\n",
      "And white to Aufi superation, hoping about M's in Vra\n",
      "Song Lord Catantsey hurt\n",
      "I know that yo' musf lucky Yuah\n",
      "Mine & now-a-umitate its begging for more\n",
      "Mysic musicy chalon feet gettin' \"Master degan\" scared can't get your dons\n",
      "Me, low at titties shit\n",
      "Pull up to the biggest life for now Wittable, I put dounging Cash stoner\n",
      "Flip the safe La, Ear, had to rusy as we used to weave\n",
      "Everyone falls in love You-usin! Erguent!\n",
      "GePreclet I make a few school\n",
      "New Billy Coby Lady's blame\n",
      "Sezen dependin' workin' out of coochie, auf I di live, it won't snatch back\n",
      "Hor pay attention, Im ran into room\n",
      "I just pop more, a Nigga, I'm self-toast Woo\n",
      "Lost is you riding?\n",
      "Don't you do to me no ass, lo-do!-G, by by\n",
      "Phycalthem\n",
      "Moving hang you out once, declini came\n",
      "\n",
      "\n",
      "All of y'all niggas cop the hat to fake it\n",
      "Man, got attention, because, i-huntry Junky, come on and fuckin' support actin' Whoo\n",
      "Feet Ooh-Ooh, I put on, fuck this pussy, god all propanx\n",
      "Merodadone\n",
      "\n",
      "\n",
      "Ohhhh, nigga, where her\n",
      "You hate a nigga thats before Jasus\n",
      "Plus I miss God say \"Quint'dles have went to MeMore langer?\n",
      "Smoke, my dirli Loc, Smack stacks power\n",
      "California, karmaa Worrying in a Medical\n",
      "Jameson pink You is scarylist\n",
      "From perfom positions like\n",
      "Waiting on a nigga lights, wrist living jogging my Arswneud beats, ahh!\n",
      "\n",
      "\n",
      "Ooh, on, ma-mana\n",
      "You're champing place!\n",
      "A Pateks mad at the top\n",
      "\n",
      "\n",
      "ONJ man, oh me, on a rehacuate\n",
      "HiV Brrr\n",
      "I fuck for Lalkers\n",
      "Baby nigga uh!\n",
      "It's the lonely roll? letting right\n",
      "It's Don levin's 'til\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Smoke \", num_generate = 1500, temperature = 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can see that different temperatures produce very different texts\n",
    "#now we can experiment with different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got the re-up\n",
      "These niggas I done popped you, nigga\n",
      "Anybody wanna talk about whe the cooling Mochers\n",
      "Might easy and watchin' that WKA, we got some baity and duct they show\n",
      "You're on your little judge, chop niggas boolin' for me Right\n",
      "Ooh, don't stop\n",
      "\n",
      "\n",
      "You wanna say that what you wanted was the one bitch, I'm in chastings\n",
      "And I'm gettin' more than that pat, mmm, ah, mmm\n",
      "I got please, that a best friend, best\n",
      "Drake said if we kicked a stick up and we can see if I tried\n",
      "Ein, me know how we became feel a rap\n",
      "That I know when the world fall for frunted with a bunch of gross\n",
      "In my players playing no pistols\n",
      "\n",
      "\n",
      "A fuck nigga, that's that shit I don't like\n",
      "Don't told me that's right, shit is miperianton\n",
      "In my life I can't let her ass in a Frendi\n",
      "Fed a flip with another liter, and the idea you dont nobody raised\n",
      "You see my damn time, the most started with you\n",
      "Locus for the fake, juggler pinnace\n",
      "Dip 'em in a corn ain't enough for me\n",
      "Ridin' 'round to talk that New York Pet, pap's over-\n",
      "I do the trum, be madef, take it with you too\n",
      "Diamonds everywhere, like before I had a groupie Yeah\n",
      "Ooh, like, \"Brrt\"\n",
      "I know you've been lyin', baby\n",
      "With you baby\n",
      "With you baby\n",
      "With you baby\n",
      "With no man shit, I enjoy this shit\n",
      "You say you a worker, woo!\n",
      "Yeah, Im lyricien: Glory\n",
      "Lady belt\n",
      "Ayy I play this chips with all the obsession's became\n",
      "Nobody tellin lies they music that lean estate\n",
      "This as I text, but I just can't give you\n",
      "I don't slip in, but you tryna kiss\n",
      "I dischull start with me\n",
      "I'm the king of my \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"I \", num_generate = 1500, temperature = 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballin knew Id makes me smile\n",
      "\n",
      "\n",
      "What's fire in? Don't get nuded off as zent B\n",
      "You caught up in cover on it with you, and now you out here made of glass up on the floors\n",
      "Group please, I be racin'\n",
      "Just get enough, just move they bitches I can't just leavin' you\n",
      "Never beat the peraps off the end is inno us\n",
      "Theres nothin water beats out a headless\n",
      "Everybody know you butterful chicken giff a team\n",
      "You were at your name\n",
      "You think I didn't be the one to talk about it?\n",
      "Which crack to seed up great\n",
      "Fuckin' with my clique, blow up that part\n",
      "Talkin' pow-pow-pop like I'm trying for me\n",
      "You a savage, hold up, yo\n",
      "The one with a real niggas making my black hole\n",
      "To all the realishing, mangu made until you're spilling\n",
      "And when I OG and I be goin' real, O's\n",
      "You ain't nothin' but a bust down\n",
      "Toes a little effer better, but still made a hat nigga\n",
      "The first and friends who will tell\n",
      "Them D's enough too many shatter and a man had the hate\n",
      "You gotta run up on the curb, it's like a hail that shit\n",
      "Don't hit your soul many baby mimmand\n",
      "So tell me whos, yes\n",
      "Soon as they love me\n",
      "There's some things that we're not around\n",
      "Uh, don't care if I live off enjoy\n",
      "I told you the dayster if I millin' niggas\n",
      "Here on this brack head\n",
      "But they said, why they do it again\n",
      "Wes, with the check penthouse\"\n",
      "My 6950 go crazy\n",
      "You told the old heir mirrors grade, The Onloh my team\n",
      "Screamin' on and I see my third eye shit\n",
      "\n",
      "\n",
      "Timber on that Hennals. AhM untim in a Wherroach\n",
      "Outside the white off\n",
      "Pull up on him off the door\n",
      "In my bank accou\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Ballin \", num_generate = 1500, temperature = 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeah when I created this, I wanna be changing the smilerd\n",
      "Edjust it cum Im doin went and ride in pecados\n",
      "In the club, rotarchip\n",
      "Yo, Pap, ya brand new Benz tell\n",
      "But my daughter too breathesh or throwed bad back\n",
      "Was the same people interfering up an advised, I always get her tough the camera\n",
      "But I know she wanna miss Nah\n",
      "I swerve, but I don't know\n",
      "But, shit, I'm still one who left me I ain't know you like michael brrr\n",
      "You never was so made the nigga having battle rap even off\n",
      "Niggas stupid with us, we notice this future; don't wanna cop it?\n",
      "My dick and you'll turn a nigga dope like my nigga\n",
      "\n",
      "\n",
      "It's how you think alone... down\n",
      "Hold on 'em, shittling dick\n",
      "Triple black trail slide Runnin' swang\n",
      "Hage neck, my bands right, right, left, left, right\n",
      "\n",
      "\n",
      "Girl!\n",
      "\n",
      "\n",
      "Mix deuce on my sneakers like boomeno Yeah\n",
      "That's why you show me why you dyin' through the naicious?\n",
      "Sever you don't really duck it behold\n",
      "Shoulda keep a lot of business of speedboat\n",
      "She a big girl, dog\n",
      "I'm gon' shine ain't always gon' tieed off\n",
      "25 or trickery, girl, this nigga been down like the Prince wit' jail\n",
      "Gettin' condoms is back to Reach!\n",
      "You scared of love\n",
      "You see me on the mattress\n",
      "Cold head, keep a king before Kequio\n",
      "\n",
      "\n",
      "I said when they sent a coda in the store\n",
      "Keep it Gufted with okay\n",
      "On the real, yo\n",
      "\n",
      "\n",
      "Ooh, ooh, oh\n",
      "\n",
      "\n",
      "How coll pop it\n",
      "But this is umbrellables, no all-song\n",
      "Is you are action, like\n",
      "\n",
      "\n",
      "Hol' up, I know a changes illue, nigga\n",
      "Too busy round's good, swallowed in privite to break that shit\n",
      "Jewel runner, riding with Ke\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Yeah \", num_generate = 1500, temperature = 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
